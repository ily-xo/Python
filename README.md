# Python Portfolio
- Welcome to my Python Repository, including some highlights from my [Data 8](http://www.data8.org/) course, Computational Models of Cognition [CogSci 131](https://classes.berkeley.edu/content/2020-spring-cogsci-131-001-lec-001) course, and more projects. I am looking forward to expanding my breadth of knowledge within the data science space. 

Some project highlights:
- Applied feature engineering techniques to enhance model performance, such as renaming columns, handling missing data, and dropping irrelevant features.
- Addressed class imbalance using the Synthetic Minority Over-sampling Technique (SMOTE) to improve model generalization on minority classes.
- Explored and trained two popular classification algorithms, Logistic Regression and XGBoost, on both the original and resampled datasets.
Utilized feature selection techniques, including SelectKBest with chi2, to reduce the dimensionality of the dataset and enhance model efficiency.
- Developed a streamlined workflow for hyperparameter tuning using RandomizedSearchCV, achieving optimal parameters for Logistic Regression (C=0.37, penalty='l2', solver='sag') and XGBoost (subsample=0.075, n_estimators=200, max_depth=10, learning_rate=0.087, colsample_bytree=0.971).
- Applied RandomizedSearchCV to the Logistic Regression model, systematically exploring different combinations of hyperparameters. Successfully identified the optimal hyperparameters for Logistic Regression, resulting in improved model accuracy and generalization. Utilized RandomizedSearchCV to fine-tune the hyperparameters of the XGBoost classification model. 
